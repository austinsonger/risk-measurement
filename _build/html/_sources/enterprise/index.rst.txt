Organizing risk
===============
Instead of focusing on a single individual, this section of documentation focuses on how a group of individuals would mitigate a risk in unison.

From the :doc:`principles </introduction/principles>` of this documentation, a single engineer working in isolation should be capable of measuring risk. They would do this by creating scenarios that describe their risks and forecasting its outcomes.

Organizations are likely to have lots of varying activities in flight that generate wildly different forms of risk. Let's take for instance, a rocket ship. Entirely different organizations and skillsets may be building the rocket, the hull, and the electronics used by astronauts.

Despite the variance in all of these disciplines, we still need to measure the likelihood that a "mission to mars" will succeed without failure.

One of the first concepts to understand when discussing large efforts around risk is the concept of "rigor" as it applies to risk measurement.

The expectation of "rigor" in measurement.
------------------------------------------
Carl Sagan once said "Extraordinary claims require extraordinary evidence". For us, extraordinary decisions follow the same principle.

A decision to launch a rocket ship is not one to be taken lightly, nor would you expect it to be the sole decision of a single individual.

Leadership can require that a decision of "Launch" may require predetermined factors that indicate that risks have been exhaustively mitigated. Some examples will be listed here, and extrapolated in the continuing documentation:

- Risks are decomposed into a register by the individuals mitigating them.
- Forecasts are gathered by individuals who have been calibration trained.
- Forecasters have a determined track record with Brier scores meeting a specific threshold.
- Historical data was sought out and modeled with frequentist approaches to inform forecasting.
- Measurement of "unknown" factors were a part of forecasts.
- A panel of individuals were relied on instead of a single individual.
- The panel included outside expertise.
- Monte carlo based uncertainty modeling was available to experts

Requiring effective forecasters.
--------------------------------
Cooke's Method.


Decomposition of risk into a register.
--------------------------------------
Given our familiarity with :doc:`scenarios </risk/scenarios>`, we understand that a natural hierarchy forms as we add conditions to a scenario.

For instance, "My house burns down tomorrow" is inherently more likely than "My house burns down tomorrow due to a grease fire". The former scenario inherently includes the conditions of the second scenario.

This aspect of scenario building is important for a chief decision maker who may decide to "Go!" a space launch. They'll need to be informed by the likelihoods of failure in several areas that could cause the mission to fail, like a rocket explosion, a hull failure, or an failure in electonic life support systems.

This can be simply modeled with simple "OR" logic operations in a spreadsheet. Visually: ::

                         ┌─────────────────────┐
                         │   Mission Success   │
                         └─────────────────────┘
                                    │
             ┌──────────────────────┼──────────────────────┐
             │                      │                      │
             ▼                      ▼                      ▼
  ┌─────────────────────┐┌─────────────────────┐┌─────────────────────┐
  │   Rocket Failure    ││     Hull Breach     ││ Electronic Failure  │
  └─────────────────────┘└─────────────────────┘└─────────────────────┘

Thus, these three example issues would be three scenarios:

- "The mission has failed due to a rocket failure. (Yes / No)"
- "The mission has failed due to a hull compromise. (Yes / No)"
- "The mission has failed due to an electronic failure. (Yes / No)"

As aerospace engineers approach a launch date, they could forecast outcomes based on proposed dates. These dates may allow for more or less testing, training, discovery of issues, etc. ::

  ┌────────────────────┐┌────────────────────┐┌────────────────────┐
  │     JAN Launch     ││     FEB Launch     ││     MAR Launch     │
  └────────────────────┘└────────────────────┘└────────────────────┘
  ┌────────────────────┐┌────────────────────┐┌────────────────────┐
  │Rocket Failure: 1%  ││Rocket Failure: .1% ││Rocket Failure: .01%│
  └────────────────────┘└────────────────────┘└────────────────────┘
  ┌────────────────────┐┌────────────────────┐┌────────────────────┐
  │Hull Breach: 1%     ││Hull Breach: .1%    ││Hull Breach: .01%   │
  └────────────────────┘└────────────────────┘└────────────────────┘
  ┌────────────────────┐┌────────────────────┐┌────────────────────┐
  │Elctrc Failure: 1%  ││Elctrc Failure: .1% ││Elctrc Failure: .01%│
  └────────────────────┘└────────────────────┘└────────────────────┘

A simple model like the above is relying on three independent probabilities which cannot be directly added. They are instead calculated with the `Inclusion / Exclusion Principle`_, however we can more easily estimate these values in a practical working environment using Monte Carlo software.

.. _Inclusion / Exclusion Principle: https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle

This sort of delegation of risk can help decouple the prescription of risk mitigations from measurement. It allows the engineers focused on "rocket failure" to achieve their highest levels of certainty by any means, as opposed to following a prescribed checklist mandated by a leadership team.


The monte carlo simulation
--------------------------
To properly estimate the likelihood of mission success for January, February, or March, you would likely use a Monte Carlo simulation. A Monte Carlo approach to this problem depends on randomized trials to estimate outcomes.

In the above case, we would be estimating the likelihood of Mission Success for each month based on its underlying probabilities.

For this, we'd get estimations of:

- January: 3% chance of mission failure.
- February: 0.3% chance of mission failure.
- March: 0.03% chance of mission failure.

As models become more complex, Monte Carlo tools allow for fast estimation without attempting to "solve" for risk mathematically. Monte Carlo methods are a powerful tool to critically inspect assumptions about risk, and help build models that can hold all of the known context about a risk.

Panels of Forecasters
---------------------
Groups of forecasters seem to benefit from the "Wisdom of Crowds" effect, and research has suggested that simple averages across multiple perspectives will have a debiasing effect on a forecast and generally improve effectiveness.

This is seen in practice with `ensemble forecasting`_ in meteorolgy.

Philip Tetlock's research into forecasting teams suggests that diversity in perspective also improves the effectiveness of forecasts.

.. _ensemble forecasting: https://en.wikipedia.org/wiki/Ensemble_forecasting

There does not need to be much to the elicitation of experts on a panel, but there are more formal approaches of panel estimations like the `Delphi method`_.

.. _Delphi Method: https://www.rand.org/topics/delphi-method.html

Panels also reduce the risk of bias towards defensive decision making, as a single individual may not even be identified in the decision as the sole actor to go forward with a decision.

Protecting against a low quality risk assessment.
-------------------------------------------------
It is highly likely that other scenarios may cause a space mission to fail, outside of the three we identified. To ensure that assessment of risk was thoroughly exhaustive, we can sample for how likely "unknown" events may cause an event.

As an example, outside of a rocket failure, hull breach, or electronics failure... one could imagine a variety of reasons that a mission may not succeed.

Within the risk register, another node can be added: ::

                         ┌─────────────────────┐
                         │   Mission Success   │
                         └─────────────────────┘
                                    │
             ┌──────────────────────┼──────────────────────┬───────────────┐
             │                      │                      │               │
             ▼                      ▼                      ▼               ▼
  ┌─────────────────────┐┌─────────────────────┐┌─────────────────────┐┌───────┐
  │   Rocket Failure    ││     Hull Breach     ││ Electronic Failure  ││   ?   │
  └─────────────────────┘└─────────────────────┘└─────────────────────┘└───────┘

If there the *other* ("?") category has an undesirable value to leadership, it may call for more rigorous risk assessment methods to identify further scenarios to measure.

An anonymous panel may be necessary in cases where individuals feel uncomfortable surfacing a previously un-measured risk. 
